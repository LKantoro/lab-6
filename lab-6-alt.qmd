---
title: "Lab 6 - Alternative"
subtitle: "Contributing to R for Data Science"
editor: source
---

The exercises from the functions below were pulled from the newest version of
[*R for Data Science*](https://r4ds.hadley.nz/). Specifically, from Chapters 25 
and 26. For this "alternative" lab you will complete the exercises from the 
textbook, with the option of submitting a pull request to the 
[repository for the textbook solutions](https://github.com/mine-cetinkaya-rundel/r4ds-solutions/).

# Vector Functions

**Question 1:** The `rescale01()` function below performs a min-max scaling to 
standardize a numeric vector, but infinite values are left unchanged. Rewrite
`rescale01()` so that `-Inf` is mapped to 0, and `Inf` is mapped to 1?
*Hint: This seems like a great place for `case_when()`!

```{r}
#| label: question-1

library(dplyr)

rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  
  #making negative infinite and infinite values the min and max, respectively
  x = case_when(x == -Inf ~ rng[1], x == Inf ~ rng[2],.default = x)
  
  (x - rng[1]) / (rng[2] - rng[1])
  
  

  
}

test_vect = c(1,-Inf,3,4,5,6,-7,8,Inf, NA)

test_vect = case_when(test_vect == -Inf ~ 0, 
                      test_vect == Inf ~ 1,.default = test_vect)

test_vect

rescale01(c(1,2,3,4,5,6,NA,-7,8,Inf, NA))
```

**Question 2:** Write a function that accepts a vector of birthdates and 
computes the age of each person in years.

```{r}
#| label: question-2

age_in_years = function(date_vect) {
  return(date_vect)
  
  
  
}

apple = c("01/01/2000", "10/23/2001")
class(apple)
apple

banana = as.Date(apple, format = "%m/%d/%yy")
banana

class(apple)
class(banana)
age_in_years(c(banana))
year(banana)

```

**Question 3:** Write a function that computes the variance and skewness of a
numeric vector. Feel free to look up the definitions on Wikipedia or elsewhere!

```{r}
#| label: question-3

library('e1071')


variance_and_skewness = function(num_vec){
  
  #if class(num_vec) != 'numeric'
  
  
  v_s_df = data.frame(Variance = var(num_vec), Skewness =  skewness(num_vec))
  
  #return(var(num_vec), skewness(num_vec))
  return(v_s_df)
}

variance_and_skewness(c(1,2,3,4,5,7,8,89,9,87,0))

var(c(1,2,3,4,5,7,8,89,9,87,0))

skewness(c(1,2,3,4,5,7,8,89,9,87,0))

class(c(1,2,3,4,5,7,8,89,9,87,0))

var(c(1,2,3,4,5,7,8,89,9,87,0))


skewness(c(1,2,3,4,5,7,8,89,9,87,0))
```

**Question 4:** Write a function called `both_na()` which takes two vectors of
the same length and returns the number of positions that have an `NA` in both
vectors.


```{r}
both_na = function(vec1, vec2){
  
  #check for if columns are same length
  
  #check for if vector is non-numeric
  
  #returns number of positions (rows) that have NA in both vectors
  
  #adding up the NA status of column 1 and column 2, then filtering by col3 = 2
  return(data.frame(vec1, vec1, 
             row_num_nas = (is.na(vec1) + is.na(vec2))) %>% 
    filter(row_num_nas == 2) %>% #  filtering by is.na(col1) + is.na(col2) = 2
    summarise(N = n()) %>% as.numeric()) # counting number of columns with 2 NAs
  
  
}

vec_a = c(NA,NA,3,4,5,6, NA)

vec_b = c(NA, NA, NA, 2,3,4,4)

data.frame(vec_a, vec_b)

is.na(vec_a) + is.na(vec_b) #equals 2 is both elements of row are NA

length(vec_a) 

#extract single value from 1x1 data frame: https://stackoverflow.com/questions/60864283/extract-the-single-value-from-a-1-x-1-data-frame-produced-with-dplyr-as-a-vector

data.frame(vec_a, vec_b, row_num_nas = (is.na(vec_a) + is.na(vec_b))) %>% filter(row_num_nas == 2) %>%
  summarise(N = n()) %>% as.numeric

both_na(vec_a, vec_b)

#find out of the number of rows that are 0 or 1 equal the length of the vectors
```



## Data Frame Functions

**Question 5:** Insert the data frame function you wrote from Lab 6 (either
Exercise 1 or Exercise 2). 

```{r}
#| label: function-from-lab-2
library(tidyverse)


impute_missing = function(df, ..., impute_fun = mean) {
  #add conditionals to make sure ... is a numeric variable
  
  newdf = df %>% 
    mutate(across(c(...), ~ replace_na(data = .x, 
                                       replace = impute_fun(.x, na.rm = TRUE))))
  return(newdf)

}

apple1 = impute_missing(nycflights13::flights, 
               arr_delay, 
               dep_delay) 

apple2 = impute_missing(nycflights13::flights, 
               arr_delay, 
               carrier)

apple3 = impute_missing(nycflights13::flights, 
               arr_delay, 
               dep_delay, 
               impute_fun = median)


table(apple1$dep_delay)
table(apple3$dep_delay)


sum(is.na(apple$arr_delay))

sum(is.na(apple$dep_delay))

mean(apple1$dep_delay)
median(apple3$dep_delay)

var(nycflights13::flights$dep_delay, na.rm = TRUE)

sum(is.na(nycflights13::flights$dep_delay))


iris %>%
  summarise(across(starts_with("Sepal"), ~ mean(.x, na.rm = TRUE)))

test = c(1, NA, 4, 5)
replace_na(data = test, replace = mean(test, na.rm = TRUE))


```

For Questions 6 - 10 you will write different functions which work with data 
similar to the `nycflights13` data. 

**Question 6:** Write a `filter_severe()` function that finds all flights that
were cancelled (i.e. `is.na(arr_time)`) or delayed by more than an hour.

```{r}
#| label: question-6

filter_severe = function(df = nycflights13::flights){
  #find all flights cancelled or delayed by more than one hour
  #departure time delayed more than one hour (dep_delay > 60)
  
  
  return(df %>% filter(is.na(arr_time) == TRUE | dep_delay > 60))
  
  
}


nycflights13::flights %>% filter(dep_delay > 60)


nycflights13::flights %>% filter(is.na(arr_time) == TRUE)


filter_severe(nycflights13::flights)



```

**Question 7:** Write a `summarize_severe()` function that counts the number of 
cancelled flights and the number of flights delayed by more than an hour.

```{r}
#| label: question-7

summarize_severe = function(df = nycflights13::flights){
  #use previous function
  
  #count number of cancelled flights
  #count number of delayed flights by more than one hour
  #two separate counts
  
  
  return(filter_severe(df) %>% summarise(N = n()))
  
}


summarize_severe(nycflights13::flights)

```

**Question 8:** Modify your `filter_severe()` function to allow the user to 
supply the number of hours that should be used to filter the flights that were
cancelled or delayed. 

```{r}
#| label: question-8

filter_severe = function(df = nycflights13::flights, hours = 1){
  #find all flights cancelled or delayed by more than one hour
  #departure time delayed more than one hour (dep_delay > 60)
  
  
  return(df %>% filter(is.na(arr_time) == TRUE | dep_delay > hours * 60))
  
  
}

filter_severe(nycflights13::flights, 1)


```

**Question 9:** Write a `summarize_weather()` function that summarizes the
weather to compute the minimum, mean, and maximum, of a user supplied variable. 

```{r}
#| label: question-9

summarize_weather = function(df = nycflights13::flights, num_var){
  #supply min, mean, max of supplied variable of a data frame
  #make sure variable is numeric
  
  #make sure variable is numeric
  
  
  #return(df %>% select(...) %>% 
  #summarise(Minimum = min(..., na.rm = TRUE),
   #         Mean = mean(..., na.rm = TRUE),
    #        Maximum = max(..., na.rm = TRUE)))
  
  return(df %>% select({{num_var}}) %>%
            summarise(Minimum = min({{num_var}}, na.rm = TRUE),
            Mean = mean({{num_var}}, na.rm = TRUE),
            Maximum = max({{num_var}}, na.rm = TRUE)))

}

summarize_weather(nycflights13::flights, dep_time)


nycflights13::flights %>% select(dep_time) %>% 
  summarise(Minimum = min(dep_time, na.rm = TRUE),
            Mean = mean(dep_time, na.rm = TRUE),
            Maximum = max(dep_time, na.rm = TRUE))

```

**Question 10:** Write a `standardize_time()` function that converts the user
supplied variable that uses clock time (e.g., `dep_time`, `arr_time`, etc.) into
a decimal time (i.e. hours + (minutes / 60)).

```{r}
#| label: question-10

standardize_time = function(df = nycflights13::flights, time_var){
  #user supplied variable that uses clock time into decimal time
  
  
  df %>% select({{time_var}}) %>% 
    mutate(dec_time = floor({{time_var}}/100) * 60 + {{time_var}} %% 100)
  
  
}

nycflights13::flights %>% select(dep_time) %>% mutate(new_time = dep_time %% 100, new_time2 = floor(dep_time/100),
                                                      final_time = floor(dep_time/100) * 60 + dep_time %% 100)
standardize_time(nycflights13::flights, dep_time)

```

# Plotting Functions

You might want to read over the [Plot Functions section of *R for Data Science*](https://r4ds.hadley.nz/functions.html#plot-functions)

**Question 11:** Build a `sorted_bars()` function which:

- takes a data frame and a variable as inputs and returns a **vertical** bar
chart 
- sorts the bars in decreasing order (largest to smallest)
- adds a title that includes the context of the variable being plotted

*Hint 1: The `fct_infreq()` and `fct_rev()` functions from the forcats package will be helpful for sorting the bars!*
*Hint 2: The `englue()` function from the rlang package will be helpful for adding a variable's name into the plot title!*

```{r}
#| label: question-11
sorted_bars <- function(df, var) {
  #vertical bar chart
  
  if {{var}} == "character"{
  }
  
  
  
  #df %>% mutate({{cat_var}} := fct_infreq({{var}})) %>% 
  #  ggplot(aes(x = {{var}})) +
  #  geom_bar()
}


sorted_bars(nycflights13::flights, carrier)


nycflights13::flights %>% mutate(carrier = fct_infreq(carrier))


class(nycflights13::flights$carrier)

class(nycflights13::flights$arr_time)

```

# Iteration

Alright, now let's take our plotting function and iterate it! 

**Question 12:** Make a sorted barplot for every character variable in the `mpg`
dataset (built into `ggplot2`). 

```{r}
#| label: question-12

```

# Contributing to the R for Data Science Community!

The functions you wrote for exercises 1-10 came from *R for Data Science*. You
could consider making a pull request to the repository for the solutions! 

<https://github.com/mine-cetinkaya-rundel/r4ds-solutions>

To learn more about how to make a pull request I would suggest this article: <https://usethis.r-lib.org/articles/pr-functions.html>
